{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://github.com/elgeish/join-audio-phonetic-embeddings/blob/master/code/train-generating-labels-best-CNN-model.ipynb (private repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# from tf.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_val, x_test = np.split(x_test, 2)\n",
    "y_val, y_test = np.split(y_test, 2)\n",
    "\n",
    "x_train, x_val, x_test = x_train / 255., x_val / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(128, activation='relu'), # if using batch norm, you have to include before using activation\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(10, activation='softmax'), \n",
    "        ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "57088/60000 [===========================>..] - ETA: 0s - loss: 0.5017 - acc: 0.8579\n",
      "Epoch 00001: saving model to weights.01.h5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.4901 - acc: 0.8613 - val_loss: 0.2985 - val_acc: 0.9140\n",
      "Epoch 2/30\n",
      "58112/60000 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9339\n",
      "Epoch 00002: saving model to weights.02.h5\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2285 - acc: 0.9344 - val_loss: 0.2183 - val_acc: 0.9356\n",
      "Epoch 3/30\n",
      "58624/60000 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9483\n",
      "Epoch 00003: saving model to weights.03.h5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.1770 - acc: 0.9485 - val_loss: 0.1818 - val_acc: 0.9444\n",
      "Epoch 4/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9569\n",
      "Epoch 00004: saving model to weights.04.h5\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.1456 - acc: 0.9569 - val_loss: 0.1541 - val_acc: 0.9520\n",
      "Epoch 5/30\n",
      "58368/60000 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9635\n",
      "Epoch 00005: saving model to weights.05.h5\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1258 - acc: 0.9636 - val_loss: 0.1393 - val_acc: 0.9590\n",
      "Epoch 6/30\n",
      "57344/60000 [===========================>..] - ETA: 0s - loss: 0.1099 - acc: 0.9669\n",
      "Epoch 00006: saving model to weights.06.h5\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.1101 - acc: 0.9669 - val_loss: 0.1261 - val_acc: 0.9634\n",
      "Epoch 7/30\n",
      "58112/60000 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9718\n",
      "Epoch 00007: saving model to weights.07.h5\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0967 - acc: 0.9716 - val_loss: 0.1198 - val_acc: 0.9614\n",
      "Epoch 8/30\n",
      "56576/60000 [===========================>..] - ETA: 0s - loss: 0.0886 - acc: 0.9738\n",
      "Epoch 00008: saving model to weights.08.h5\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0881 - acc: 0.9740 - val_loss: 0.1140 - val_acc: 0.9646\n",
      "Epoch 9/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9760\n",
      "Epoch 00009: saving model to weights.09.h5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0790 - acc: 0.9761 - val_loss: 0.1092 - val_acc: 0.9652\n",
      "Epoch 10/30\n",
      "57600/60000 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9784\n",
      "Epoch 00010: saving model to weights.10.h5\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.0713 - acc: 0.9783 - val_loss: 0.1030 - val_acc: 0.9698\n",
      "Epoch 11/30\n",
      "58368/60000 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9795\n",
      "Epoch 00011: saving model to weights.11.h5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0672 - acc: 0.9797 - val_loss: 0.1073 - val_acc: 0.9654\n",
      "Epoch 12/30\n",
      "58624/60000 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9811\n",
      "Epoch 00012: saving model to weights.12.h5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0620 - acc: 0.9812 - val_loss: 0.0975 - val_acc: 0.9686\n",
      "Epoch 13/30\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9823\n",
      "Epoch 00013: saving model to weights.13.h5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0583 - acc: 0.9823 - val_loss: 0.1015 - val_acc: 0.9666\n",
      "Epoch 14/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9832\n",
      "Epoch 00014: saving model to weights.14.h5\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0540 - acc: 0.9831 - val_loss: 0.0951 - val_acc: 0.9700\n",
      "Epoch 15/30\n",
      "58624/60000 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9849\n",
      "Epoch 00015: saving model to weights.15.h5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0499 - acc: 0.9849 - val_loss: 0.0969 - val_acc: 0.9692\n",
      "Epoch 16/30\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9849\n",
      "Epoch 00016: saving model to weights.16.h5\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0482 - acc: 0.9849 - val_loss: 0.0976 - val_acc: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150fe6ed0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # multiclassification loss is sum of cross entropy terms \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2), \n",
    "    ModelCheckpoint(filepath='weights.{epoch:02d}.h5', monitor='val_loss', verbose=1), # very important, it saves snapshot of model into a file\n",
    "]\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "session = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(session)\n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "history = model.fit(x=x_train, y=y_train, epochs=30, callbacks=callbacks, batch_size=256, validation_data=(x_val, y_val))\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_data': None,\n",
       " 'model': <tensorflow.python.keras.engine.sequential.Sequential at 0x130da61d0>,\n",
       " '_chief_worker_only': None,\n",
       " 'params': {'batch_size': 256,\n",
       "  'epochs': 30,\n",
       "  'steps': None,\n",
       "  'samples': 60000,\n",
       "  'verbose': 0,\n",
       "  'do_validation': True,\n",
       "  'metrics': ['loss', 'acc', 'val_loss', 'val_acc']},\n",
       " 'epoch': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       " 'history': {'loss': [0.49009291586875914,\n",
       "   0.2285001353462537,\n",
       "   0.17695056507587434,\n",
       "   0.14563402893940608,\n",
       "   0.1257994885603587,\n",
       "   0.11008274061282476,\n",
       "   0.09674667792121569,\n",
       "   0.08810764939983685,\n",
       "   0.07903793173233668,\n",
       "   0.07130728961030643,\n",
       "   0.0671675094683965,\n",
       "   0.06199074526230494,\n",
       "   0.05832368573943774,\n",
       "   0.05396182544231415,\n",
       "   0.04988664613962174,\n",
       "   0.04818193860650063],\n",
       "  'acc': [0.86135,\n",
       "   0.93435,\n",
       "   0.94846666,\n",
       "   0.9569333,\n",
       "   0.96358335,\n",
       "   0.96688336,\n",
       "   0.9716167,\n",
       "   0.97398335,\n",
       "   0.97608334,\n",
       "   0.97833335,\n",
       "   0.97968334,\n",
       "   0.98125,\n",
       "   0.9823167,\n",
       "   0.9831167,\n",
       "   0.9849167,\n",
       "   0.9849],\n",
       "  'val_loss': [0.2985289279937744,\n",
       "   0.2183088826417923,\n",
       "   0.1818128098964691,\n",
       "   0.15406674308776855,\n",
       "   0.13928023874759674,\n",
       "   0.12607919425964356,\n",
       "   0.11980858983993531,\n",
       "   0.11404892194271088,\n",
       "   0.10923303326368332,\n",
       "   0.1030381587922573,\n",
       "   0.10726911103725434,\n",
       "   0.09747219151258468,\n",
       "   0.10152587834596634,\n",
       "   0.09509774742722511,\n",
       "   0.09693816075325012,\n",
       "   0.09757164165973663],\n",
       "  'val_acc': [0.914,\n",
       "   0.9356,\n",
       "   0.9444,\n",
       "   0.952,\n",
       "   0.959,\n",
       "   0.9634,\n",
       "   0.9614,\n",
       "   0.9646,\n",
       "   0.9652,\n",
       "   0.9698,\n",
       "   0.9654,\n",
       "   0.9686,\n",
       "   0.9666,\n",
       "   0.97,\n",
       "   0.9692,\n",
       "   0.9686]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
